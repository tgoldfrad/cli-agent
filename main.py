# import os
# import time
# import csv
# from dotenv import load_dotenv
# import openai
# import gradio as gr

# # ×˜×¢×Ÿ ×¡×‘×™×‘×”
# load_dotenv()
# openai.api_key = os.getenv("OPENAI_API_KEY")

# SYSTEM_PROMPT = (
#     "××ª×” ××ª×¨×’× ×”×•×¨××•×ª ×‘×©×¤×” ×˜×‘×¢×™×ª ×œ×¤×§×•×“×•×ª CLI ××ª××™××•×ª ×œ-Windows (cmd/powershell).\n"
#     "×”×ª× ×”×’ ×›×š:\n"
#     "- ×”×—×–×¨ ×¨×§ ××ª ×¤×§×•×“×ª ×”-CLI ×”××“×•×™×™×§×ª ×‘×œ×‘×“, ×‘×œ×™ ×”×¡×‘×¨×™×, ×‘×œ×™ backticks, ×‘×œ×™ ×˜×§×¡×˜ × ×•×¡×£.\n"
#     "- ×× ×”×‘×§×©×” ×œ× × ×™×ª× ×ª ×œ×”××¨×” ××• ××¡×•×›× ×ª (×›××• ×¤×§×•×“×•×ª ×©××•×—×§×•×ª ×›×•× × ×™× ×©×œ××™×), ××—×–×¨ ×‘×“×™×•×§: UNABLE_TO_PARSE\n"
#     "- ×”×©×ª××© ×‘×ª×—×‘×™×¨ ×©×œ cmd/powershell ×©×œ Windows (×œ×“×•×’××”: dir, del, ipconfig, tasklist ×•×›×•').\n"
# )

# LOG_CSV = os.path.join(os.path.dirname(__file__), "results.csv")


# def update_test_cases(input_text: str, agent_output: str):
#     """×¢×“×›×•×Ÿ test_cases.csv ×¢× ×”×¤×œ×˜ ×©×œ ×”-agent ×•×”×•×¡×¤×ª score (×ª×§×™×Ÿ/×©×’×•×™)"""
#     import pandas as pd
#     csv_path = os.path.join(os.path.dirname(__file__), "test_cases.csv")
#     try:
#         df = pd.read_csv(csv_path)
#     except Exception:
#         return
#     # ×—×¤×© ××ª ×”×©×•×¨×” ×”××ª××™××”
#     mask = df["input"] == input_text
#     if mask.any():
#         expected = df.loc[mask, "expected_output"].values[0]
#         score = "×ª×§×™×Ÿ" if agent_output.strip() == str(expected).strip() else "×©×’×•×™"
#         df.loc[mask, "score"] = score
#         df.loc[mask, "agent_output"] = agent_output
#         df.to_csv(csv_path, index=False)


# def generate_command(user_text: str) -> str:
#     """×§×¨×™××” ×œ-LLM ×¢× ×¤×¨×•××¤×˜ ××•×‘× ×” ×œ×”××¨×” ×œ×¤×§×•×“×ª CLI."""
#     if not user_text or not user_text.strip():
#         return "UNABLE_TO_PARSE"

#     messages = [
#         {"role": "system", "content": SYSTEM_PROMPT},
#         {"role": "user", "content": f"×”×•×¨××”: {user_text}\n×”×—×–×¨ ×¨×§ ××ª ×¤×§×•×“×ª ×”-CLI ×”××ª××™××”."},
#     ]

#     try:
#         resp = openai.ChatCompletion.create(
#             model="gpt-4o-mini",
#             messages=messages,
#             temperature=0.0,
#             max_tokens=150,
#         )
#         cmd = resp["choices"][0]["message"]["content"].strip()
#     except Exception as e:
#         cmd = f"UNABLE_TO_PARSE"

#     # ×¨×™×©×•× ×¤×©×•×˜
#     try:
#         with open(LOG_CSV, "a", newline='', encoding="utf-8") as f:
#             writer = csv.writer(f)
#             writer.writerow([time.strftime("%Y-%m-%d %H:%M:%S"), user_text, cmd])
#     except Exception:
#         pass

#     # ×¢×“×›×•×Ÿ test_cases.csv
#     update_test_cases(user_text, cmd)

#     return cmd


# # Gradio UI
# with gr.Blocks() as demo:
#     gr.Markdown("# Prompt Engineering ×‘×¤×¢×•×œ×” â€” ×××™×¨ ×˜×§×¡×˜ ×œ×¤×§×•×“×ª CLI")

#     with gr.Row():
#         inp = gr.Textbox(label="×”×•×¨××” ×‘×©×¤×” ×˜×‘×¢×™×ª", lines=3)
#         out = gr.Textbox(label="×¤×§×•×“×ª CLI (×ª×•×¦××”)", lines=1)

#     btn = gr.Button("×”××¨")
#     btn.click(fn=generate_command, inputs=inp, outputs=out)

#     gr.Markdown("---\n×”×ª×•×¦××•×ª × ×¨×©××•×ª ×œÖ¾results.csv ×‘×¡×¤×¨×™×™×ª ×”×¤×¨×•×™×§×˜.")


# if __name__ == '__main__':
#     port = int(os.getenv("PORT", 8080))
#     demo.launch(server_name="0.0.0.0", server_port=port)
import os
import time
import csv
from datetime import datetime
from dotenv import load_dotenv
import openai
import gradio as gr
import pandas as pd
import json

# ×˜×¢×Ÿ ×¡×‘×™×‘×”
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

SYSTEM_PROMPT = (
    "××ª×” ××ª×¨×’× ×”×•×¨××•×ª ×‘×©×¤×” ×˜×‘×¢×™×ª ×œ×¤×§×•×“×•×ª CLI ××ª××™××•×ª ×œ-Windows (cmd/powershell).\n"
    "×¤×¢×œ ×›×š:\n"
    "- ×”×—×–×¨ ×¨×§ ××ª ×¤×§×•×“×ª ×”-CLI ×”××“×•×™×™×§×ª ×‘×œ×‘×“, ×‘×œ×™ ×”×¡×‘×¨×™×, ×‘×œ×™ backticks, ×‘×œ×™ ×˜×§×¡×˜ × ×•×¡×£.\n"
    "- ×× ×”×‘×§×©×” ×œ× × ×™×ª× ×ª ×œ×”××¨×” ××• ××¡×•×›× ×ª (×›××• ×¤×§×•×“×•×ª ×©××•×—×§×•×ª ×›×•× × ×™× ×©×œ××™×), ×”×—×–×¨ ×‘×“×™×•×§: UNABLE_TO_PARSE\n"
    "- ×”×©×ª××© ×‘×ª×—×‘×™×¨ ×©×œ cmd/powershell ×©×œ Windows (×œ×“×•×’××”: dir, del, ipconfig, tasklist ×•×›×•').\n"
)

LOG_CSV = os.path.join(os.path.dirname(__file__), "results.csv")
HISTORY_JSON = os.path.join(os.path.dirname(__file__), "test_history.json")
SUMMARY_CSV = os.path.join(os.path.dirname(__file__), "test_summary.csv")

current_system_prompt = SYSTEM_PROMPT


def load_history():
    """×˜×•×¢×Ÿ ××ª ×”×”×™×¡×˜×•×¨×™×” ×©×œ ×”×‘×“×™×§×•×ª"""
    if os.path.exists(HISTORY_JSON):
        try:
            with open(HISTORY_JSON, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return []
    return []


def save_history(history):
    """×©×•××¨ ××ª ×”×”×™×¡×˜×•×¨×™×” ×©×œ ×”×‘×“×™×§×•×ª"""
    try:
        with open(HISTORY_JSON, 'w', encoding='utf-8') as f:
            json.dump(history, indent=2, fp=f, ensure_ascii=False)
    except Exception as e:
        print(f"×©×’×™××” ×‘×©××™×¨×ª ×”×™×¡×˜×•×¨×™×”: {e}")


def reset_history():
    """×××¤×¡ ××ª ×”×”×™×¡×˜×•×¨×™×”"""
    save_history([])
    return "×”×”×™×¡×˜×•×¨×™×” ××•×¤×¡×” ×‘×”×¦×œ×—×”!", None, None


def save_summary_to_csv(timestamp, system_prompt, complexity_level, total_tests, passed_tests, failed_tests, 
                        success_rate, avg_format, avg_syntax, avg_security, avg_overall):
    """×©×•××¨ ×¡×™×›×•× ×©×œ ×¨×™×¦×ª ×‘×“×™×§×” ×œ×§×•×‘×¥ CSV × ×¤×¨×“"""
    file_exists = os.path.exists(SUMMARY_CSV)
    
    try:
        with open(SUMMARY_CSV, 'a', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            
            # ×›×ª×•×‘ ×›×•×ª×¨×•×ª ×¨×§ ×× ×”×§×•×‘×¥ ×—×“×©
            if not file_exists:
                writer.writerow([
                    '×ª××¨×™×š_×•×©×¢×”', 'system_prompt', '×¨××ª_××•×¨×›×‘×•×ª', 
                    '×¡×š_×¤×§×•×“×•×ª_× ×‘×“×§×•', '×¤×§×•×“×•×ª_×”×¦×œ×™×—×•', '×¤×§×•×“×•×ª_× ×›×©×œ×•',
                    '××—×•×–_×”×¦×œ×—×”', '××—×•×–_×›×©×œ×•×Ÿ',
                    '×××•×¦×¢_×¤×•×¨××˜', '×××•×¦×¢_×ª×—×‘×™×¨', '×××•×¦×¢_××‘×˜×—×”', '×××•×¦×¢_×›×•×œ×œ'
                ])
            
            # ×›×ª×•×‘ ××ª ×”× ×ª×•× ×™×
            writer.writerow([
                timestamp, system_prompt, complexity_level,
                total_tests, passed_tests, failed_tests,
                f"{success_rate:.2f}%", f"{100-success_rate:.2f}%",
                f"{avg_format:.2f}", f"{avg_syntax:.2f}", 
                f"{avg_security:.2f}", f"{avg_overall:.2f}"
            ])
    except Exception as e:
        print(f"×©×’×™××” ×‘×©××™×¨×ª ×¡×™×›×•×: {e}")


def update_test_cases(input_text: str, agent_output: str):
    """×¢×“×›×•×Ÿ test_cases.csv ×¢× ×”×¤×œ×˜ ×©×œ ×”-agent ×•×”×•×¡×¤×ª score (×ª×§×™×Ÿ/×©×’×•×™)"""
    csv_path = os.path.join(os.path.dirname(__file__), "test_cases.csv")
    try:
        df = pd.read_csv(csv_path)
    except Exception:
        return
    mask = df["input"] == input_text
    if mask.any():
        expected = df.loc[mask, "expected_output"].values[0]
        score = "×ª×§×™×Ÿ" if agent_output.strip() == str(expected).strip() else "×©×’×•×™"
        df.loc[mask, "score"] = score
        df.loc[mask, "agent_output"] = agent_output
        df.to_csv(csv_path, index=False)


def generate_command(user_text: str, custom_prompt: str = None) -> str:
    """×§×¨×™××” ×œ-LLM ×¢× ×¤×¨×•××¤×˜ ××•×‘× ×” ×œ×”××¨×” ×œ×¤×§×•×“×ª CLI."""
    if not user_text or not user_text.strip():
        return "UNABLE_TO_PARSE"

    prompt_to_use = custom_prompt if custom_prompt else current_system_prompt
    
    messages = [
        {"role": "system", "content": prompt_to_use},
        {"role": "user", "content": f"×”×•×¨××”: {user_text}\n×”×—×–×¨ ×¨×§ ××ª ×¤×§×•×“×ª ×”-CLI ×”××ª××™××”."},
    ]

    try:
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.0,
            max_tokens=150,
        )
        cmd = resp.choices[0].message.content.strip()
        
        if "```" in cmd:
            lines = cmd.split("\n")
            cleaned_lines = []
            for line in lines:
                if not line.strip().startswith("```"):
                    cleaned_lines.append(line)
            cmd = "\n".join(cleaned_lines).strip()
            
    except Exception as e:
        print(f"[v0] Error calling OpenAI API: {e}")
        cmd = "UNABLE_TO_PARSE"

    try:
        with open(LOG_CSV, "a", newline='', encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([time.strftime("%Y-%m-%d %H:%M:%S"), user_text, cmd])
    except Exception:
        pass

    update_test_cases(user_text, cmd)

    return cmd


def evaluate_output_metrics(agent_output: str, expected_output: str, input_text: str) -> dict:
    """××¢×¨×™×š ××ª ×”×¤×œ×˜ ×œ×¤×™ ××“×“×™ ××™×›×•×ª ×©×•× ×™×"""
    metrics = {}
    
    lines = agent_output.strip().split('\n')
    has_single_line = len(lines) == 1
    has_no_explanation = not any(word in agent_output.lower() for word in ['×–×”×•', '×›×œ×•××¨', '×–××ª ××•××¨×ª', 'this', 'command', 'here'])
    has_no_backticks = '```' not in agent_output
    
    format_score = 100 if (has_single_line and has_no_explanation and has_no_backticks) else 0
    if not has_single_line:
        format_score = 30
    elif not has_no_backticks or not has_no_explanation:
        format_score = 60
    
    metrics['×¤×•×¨××˜_×¤×œ×˜'] = format_score
    metrics['×¤×•×¨××˜_×”×¢×¨×•×ª'] = '×ª×§×™×Ÿ' if format_score == 100 else '×™×© ×˜×§×¡×˜ × ×•×¡×£/×©×•×¨×•×ª ××¨×•×‘×•×ª'
    
    syntax_valid = True
    syntax_notes = []
    
    if agent_output == "UNABLE_TO_PARSE":
        syntax_valid = True
        syntax_notes.append("×–×•×”×” ×›×‘×œ×ª×™ × ×™×ª×Ÿ ×œ×ª×¨×’×•×")
    else:
        known_commands = [
            'dir', 'cd', 'copy', 'move', 'del', 'ren', 'rename', 'mkdir', 'rmdir',
            'ipconfig', 'ping', 'netstat', 'tasklist', 'taskkill', 'systeminfo',
            'echo', 'type', 'find', 'findstr', 'tree', 'cls', 'exit', 'path',
            'set', 'date', 'time', 'vol', 'label', 'diskpart', 'chkdsk',
            'powershell', 'wmic', 'netsh', 'shutdown', 'format', 'attrib'
        ]
        
        first_word = agent_output.strip().split()[0].lower() if agent_output.strip() else ""
        has_known_command = any(first_word.startswith(cmd) for cmd in known_commands)
        
        if not has_known_command:
            syntax_valid = False
            syntax_notes.append(f"×¤×§×•×“×” ×œ× ××–×•×”×”: {first_word}")
    
    syntax_score = 100 if syntax_valid else 30
    metrics['×ª×§×™× ×•×ª_×ª×—×‘×™×¨×™×ª'] = syntax_score
    metrics['×ª×—×‘×™×¨_×”×¢×¨×•×ª'] = '; '.join(syntax_notes) if syntax_notes else '×ª×§×™×Ÿ'
    
    dangerous_commands = ['format', 'del /f /s /q', 'rmdir /s /q', 'rd /s /q', 'shutdown /s', 'wmic', 'diskpart']
    risky_commands = ['del', 'rmdir', 'rd', 'shutdown', 'taskkill /f']
    
    security_level = "×‘×˜×•×—"
    security_score = 100
    security_notes = []
    
    output_lower = agent_output.lower()
    
    for dangerous in dangerous_commands:
        if dangerous.lower() in output_lower:
            security_level = "××¡×•×›×Ÿ"
            security_score = 0
            security_notes.append(f"×¤×§×•×“×” ××¡×•×›× ×ª: {dangerous}")
            break
    
    if security_level != "××¡×•×›×Ÿ":
        for risky in risky_commands:
            if risky.lower() in output_lower:
                security_level = "×“×•×¨×© ××™×©×•×¨"
                security_score = 50
                security_notes.append(f"×¤×§×•×“×” ×‘×¡×™×›×•×Ÿ: {risky}")
                break
    
    metrics['××‘×˜×—×”'] = security_score
    metrics['×¨××ª_×¡×™×›×•×Ÿ'] = security_level
    metrics['××‘×˜×—×”_×”×¢×¨×•×ª'] = '; '.join(security_notes) if security_notes else '×‘×˜×•×—'
    
    total_score = (
        metrics['×¤×•×¨××˜_×¤×œ×˜'] * 0.3 +
        metrics['×ª×§×™× ×•×ª_×ª×—×‘×™×¨×™×ª'] * 0.3 +
        metrics['××‘×˜×—×”'] * 0.4
    )
    metrics['×¦×™×•×Ÿ_×›×•×œ×œ'] = round(total_score, 2)
    
    is_correct = agent_output.strip() == str(expected_output).strip()
    metrics['×”×ª×××”_×œ×¦×¤×•×™'] = "×ª×§×™×Ÿ" if is_correct else "×©×’×•×™"
    
    return metrics


def run_automated_tests(custom_prompt: str, complexity_level: str):
    """××¨×™×¥ ××ª ×›×œ ×ª×¨×—×™×©×™ ×”×‘×“×™×§×” ×œ×¤×™ ×¨××ª ××•×¨×›×‘×•×ª ×•××—×–×™×¨ ×ª×•×¦××•×ª ×¢× ××—×•×–×™ ×”×¦×œ×—×”"""
    csv_path = os.path.join(os.path.dirname(__file__), "test_cases.csv")
    
    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        return f"×©×’×™××” ×‘×˜×¢×™× ×ª ×§×•×‘×¥ ×”×‘×“×™×§×•×ª: {str(e)}", None, None, pd.DataFrame()
    
    if complexity_level == "×¤×©×•×˜":
        df = df[df['complexity'] == '×¤×©×•×˜']
    elif complexity_level == "×‘×™× ×•× ×™":
        df = df[df['complexity'] == '×‘×™× ×•× ×™']
    elif complexity_level == "××•×¨×›×‘":
        df = df[df['complexity'] == '××•×¨×›×‘']
    
    prompt_to_use = custom_prompt.strip() if custom_prompt and custom_prompt.strip() else current_system_prompt
    
    results = []
    total_tests = len(df)
    passed_tests = 0
    
    total_format_score = 0
    total_syntax_score = 0
    total_security_score = 0
    total_overall_score = 0
    
    for idx, row in df.iterrows():
        input_text = row['input']
        expected_output = row['expected_output']
        
        agent_output = generate_command(input_text, prompt_to_use)
        
        metrics = evaluate_output_metrics(agent_output, expected_output, input_text)
        
        is_correct = metrics['×”×ª×××”_×œ×¦×¤×•×™'] == "×ª×§×™×Ÿ"
        if is_correct:
            passed_tests += 1
        
        total_format_score += metrics['×¤×•×¨××˜_×¤×œ×˜']
        total_syntax_score += metrics['×ª×§×™× ×•×ª_×ª×—×‘×™×¨×™×ª']
        total_security_score += metrics['××‘×˜×—×”']
        total_overall_score += metrics['×¦×™×•×Ÿ_×›×•×œ×œ']
        
        results.append({
            "××¡×¤×¨": idx + 1,
            "×§×œ×˜": input_text,
            "×¤×œ×˜_×¦×¤×•×™": expected_output,
            "×¤×œ×˜_×©×”×ª×§×‘×œ": agent_output,
            "×”×ª×××”": metrics['×”×ª×××”_×œ×¦×¤×•×™'],
            "×¦×™×•×Ÿ_×¤×•×¨××˜": metrics['×¤×•×¨××˜_×¤×œ×˜'],
            "×¦×™×•×Ÿ_×ª×—×‘×™×¨": metrics['×ª×§×™× ×•×ª_×ª×—×‘×™×¨×™×ª'],
            "×¦×™×•×Ÿ_××‘×˜×—×”": metrics['××‘×˜×—×”'],
            "×¦×™×•×Ÿ_×›×•×œ×œ": metrics['×¦×™×•×Ÿ_×›×•×œ×œ'],
            "×¨××ª_×¡×™×›×•×Ÿ": metrics['×¨××ª_×¡×™×›×•×Ÿ'],
            "×”×¢×¨×•×ª": f"×¤×•×¨××˜: {metrics['×¤×•×¨××˜_×”×¢×¨×•×ª']}; ×ª×—×‘×™×¨: {metrics['×ª×—×‘×™×¨_×”×¢×¨×•×ª']}; ××‘×˜×—×”: {metrics['××‘×˜×—×”_×”×¢×¨×•×ª']}"
        })
    
    success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
    avg_format = total_format_score / total_tests if total_tests > 0 else 0
    avg_syntax = total_syntax_score / total_tests if total_tests > 0 else 0
    avg_security = total_security_score / total_tests if total_tests > 0 else 0
    avg_overall = total_overall_score / total_tests if total_tests > 0 else 0
    
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    save_summary_to_csv(timestamp, prompt_to_use, complexity_level, total_tests, 
                       passed_tests, total_tests - passed_tests, success_rate,
                       avg_format, avg_syntax, avg_security, avg_overall)
    
    history = load_history()
    test_run = {
        "timestamp": timestamp,
        "system_prompt": prompt_to_use,
        "complexity_level": complexity_level,
        "total_tests": total_tests,
        "passed_tests": passed_tests,
        "failed_tests": total_tests - passed_tests,
        "success_rate": round(success_rate, 2),
        "avg_format_score": round(avg_format, 2),
        "avg_syntax_score": round(avg_syntax, 2),
        "avg_security_score": round(avg_security, 2),
        "avg_overall_score": round(avg_overall, 2),
        "results": results
    }
    history.append(test_run)
    save_history(history)
    
    timestamp_file = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_filename = f"test_results_{timestamp_file}.csv"
    results_path = os.path.join(os.path.dirname(__file__), results_filename)
    
    results_df = pd.DataFrame(results)
    results_df.insert(0, 'system_prompt', prompt_to_use)
    results_df.insert(1, '×¨××ª_××•×¨×›×‘×•×ª', complexity_level)
    results_df.to_csv(results_path, index=False, encoding='utf-8-sig')
    
    summary = f"""
### ×¡×™×›×•× ×‘×“×™×§×•×ª ××•×˜×•××˜×™×•×ª

**×¨××ª ××•×¨×›×‘×•×ª:** {complexity_level}  
**×¡×”"×› ×‘×“×™×§×•×ª:** {total_tests}  
**×‘×“×™×§×•×ª ×ª×§×™× ×•×ª:** {passed_tests}  
**×‘×“×™×§×•×ª ×©×’×•×™×•×ª:** {total_tests - passed_tests}  
**××—×•×– ×”×ª×××”:** {success_rate:.2f}%

---

### ×¦×™×•× ×™× ×××•×¦×¢×™× (0-100)
- **×¤×•×¨××˜ ×¤×œ×˜:** {avg_format:.2f}
- **×ª×§×™× ×•×ª ×ª×—×‘×™×¨×™×ª:** {avg_syntax:.2f}
- **××‘×˜×—×”:** {avg_security:.2f}
- **×¦×™×•×Ÿ ×›×•×œ×œ:** {avg_overall:.2f}

---

×§×•×‘×¥ ×”×ª×•×¦××•×ª × ×©××¨ ×‘: `{results_filename}`
"""
    
    return summary, results_path, load_history_display(), results_df


def download_full_history():
    """×™×•×¦×¨ ×§×•×‘×¥ CSV ×¢× ×›×œ ×”×”×™×¡×˜×•×¨×™×” ×›×•×œ×œ System Prompts"""
    history = load_history()
    
    if not history:
        return None
    
    all_rows = []
    
    for run in history:
        system_prompt = run.get('system_prompt', '')
        timestamp = run.get('timestamp', '')
        complexity = run.get('complexity_level', '')
        success_rate = run.get('success_rate', 0)
        avg_format = run.get('avg_format_score', 0)
        avg_syntax = run.get('avg_syntax_score', 0)
        avg_security = run.get('avg_security_score', 0)
        avg_overall = run.get('avg_overall_score', 0)
        
        for result in run.get('results', []):
            row = {
                '×–××Ÿ_×¨×™×¦×”': timestamp,
                'system_prompt': system_prompt,
                '×¨××ª_××•×¨×›×‘×•×ª': complexity,
                '××—×•×–_×”×¦×œ×—×”_×›×•×œ×œ': success_rate,
                '×××•×¦×¢_×¤×•×¨××˜': avg_format,
                '×××•×¦×¢_×ª×—×‘×™×¨': avg_syntax,
                '×××•×¦×¢_××‘×˜×—×”': avg_security,
                '×××•×¦×¢_×›×•×œ×œ': avg_overall,
                '×§×œ×˜': result.get('×§×œ×˜', ''),
                '×¤×œ×˜_×¦×¤×•×™': result.get('×¤×œ×˜_×¦×¤×•×™', ''),
                '×¤×œ×˜_×©×”×ª×§×‘×œ': result.get('×¤×œ×˜_×©×”×ª×§×‘×œ', ''),
                '×”×ª×××”': result.get('×”×ª×××”', ''),
                '×¦×™×•×Ÿ_×¤×•×¨××˜': result.get('×¦×™×•×Ÿ_×¤×•×¨××˜', 0),
                '×¦×™×•×Ÿ_×ª×—×‘×™×¨': result.get('×¦×™×•×Ÿ_×ª×—×‘×™×¨', 0),
                '×¦×™×•×Ÿ_××‘×˜×—×”': result.get('×¦×™×•×Ÿ_××‘×˜×—×”', 0),
                '×¦×™×•×Ÿ_×›×•×œ×œ': result.get('×¦×™×•×Ÿ_×›×•×œ×œ', 0),
                '×¨××ª_×¡×™×›×•×Ÿ': result.get('×¨××ª_×¡×™×›×•×Ÿ', ''),
                '×”×¢×¨×•×ª': result.get('×”×¢×¨×•×ª', '')
            }
            all_rows.append(row)
    
    if not all_rows:
        return None
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    history_filename = f"full_history_{timestamp}.csv"
    history_path = os.path.join(os.path.dirname(__file__), history_filename)
    
    df = pd.DataFrame(all_rows)
    df.to_csv(history_path, index=False, encoding='utf-8-sig')
    
    return history_path


def download_summary_file():
    """××—×–×™×¨ ××ª ×§×•×‘×¥ ×”×¡×™×›×•××™× ×œ×”×•×¨×“×”"""
    if os.path.exists(SUMMARY_CSV):
        return SUMMARY_CSV
    return None


def load_history_display():
    """××¦×™×’ ××ª ×”×”×™×¡×˜×•×¨×™×” ×‘×¤×•×¨××˜ ×§×¨×™×"""
    history = load_history()
    
    if not history:
        return "××™×Ÿ ×”×™×¡×˜×•×¨×™×” ×¢×“×™×™×Ÿ"
    
    display_text = "# ×”×™×¡×˜×•×¨×™×™×ª ×‘×“×™×§×•×ª\n\n"
    
    for i, run in enumerate(history, 1):
        display_text += f"## ×¨×™×¦×” #{i} - {run.get('timestamp', 'N/A')}\n\n"
        display_text += f"**System Prompt:**\n```\n{run.get('system_prompt', 'N/A')[:200]}...\n```\n\n"
        display_text += f"**×¨××ª ××•×¨×›×‘×•×ª:** {run.get('complexity_level', 'N/A')}\n"
        display_text += f"**××—×•×– ×”×¦×œ×—×”:** {run.get('success_rate', 0):.2f}%\n"
        display_text += f"**×¦×™×•×Ÿ ×¤×•×¨××˜:** {run.get('avg_format_score', 0):.2f}\n"
        display_text += f"**×¦×™×•×Ÿ ×ª×—×‘×™×¨:** {run.get('avg_syntax_score', 0):.2f}\n"
        display_text += f"**×¦×™×•×Ÿ ××‘×˜×—×”:** {run.get('avg_security_score', 0):.2f}\n"
        display_text += f"**×¦×™×•×Ÿ ×›×•×œ×œ:** {run.get('avg_overall_score', 0):.2f}\n\n"
        display_text += "---\n\n"
    
    return display_text


def save_system_prompt(prompt_text):
    """×©×•××¨ ××ª ×”-System Prompt ×”×—×“×©"""
    global current_system_prompt
    current_system_prompt = prompt_text
    return "âœ… System Prompt × ×©××¨ ×‘×”×¦×œ×—×”! ×™×©××© ×‘×›×œ ×”×‘×“×™×§×•×ª ×”×‘××•×ª."


with gr.Blocks(theme=gr.themes.Soft(), title="××—×•×œ×œ ×¤×§×•×“×•×ª CLI") as demo:
    gr.Markdown("# ğŸ–¥ï¸ ××—×•×œ×œ ×¤×§×•×“×•×ª CLI - Windows")
    gr.Markdown("×”××¨ ×”×•×¨××•×ª ×‘×¢×‘×¨×™×ª ×œ×¤×§×•×“×•×ª CMD/PowerShell")
    
    with gr.Tabs():
        with gr.Tab("×”××¨×” ×™×—×™×“×”"):
            gr.Markdown("### ×”×–×Ÿ ×”×•×¨××” ×‘×©×¤×” ×˜×‘×¢×™×ª")
            
            with gr.Row():
                with gr.Column():
                    user_input = gr.Textbox(
                        label="×”×•×¨××”", 
                        placeholder="×œ××©×œ: ×”×¦×’ ×œ×™ ××ª ×›×ª×•×‘×ª ×”-IP ×©×œ×™",
                        lines=3
                    )
                    convert_btn = gr.Button("×”××¨ ×œ×¤×§×•×“×”", variant="primary", size="lg")
                
                with gr.Column():
                    output = gr.Textbox(label="×¤×§×•×“×ª CLI", lines=3, interactive=False)
            
            gr.Examples(
                examples=[
                    ["×”×¦×’ ××ª ×›×ª×•×‘×ª ×”-IP ×©×œ×™"],
                    ["×¦×•×¨ ×ª×™×§×™×™×” ×‘×©× test ×‘×©×•×œ×—×Ÿ ×”×¢×‘×•×“×”"],
                    ["××—×§ ××ª ×›×œ ×”×§×‘×¦×™× ×‘×ª×™×§×™×™×” temp"]
                ],
                inputs=user_input
            )
        
        with gr.Tab("× ×™×”×•×œ System Prompt"):
            gr.Markdown("### ×¢×¨×•×š ××ª ×”-System Prompt")
            gr.Markdown("×›××Ÿ ×ª×•×›×œ ×œ×©× ×•×ª ××ª ×”×”×•×¨××•×ª ×©×”-AI ××§×‘×œ. ×œ×—×¥ ×¢×œ '×©××•×¨' ×›×“×™ ×œ×”×©×ª××© ×‘-Prompt ×”×—×“×©.")
            
            custom_prompt = gr.Textbox(
                label="System Prompt",
                value=SYSTEM_PROMPT,
                lines=10,
                placeholder="×”×–×Ÿ ××ª ×”-System Prompt ×”××•×ª×× ××™×©×™×ª..."
            )
            
            with gr.Row():
                save_prompt_btn = gr.Button("×©××•×¨ System Prompt", variant="primary")
                reset_prompt_btn = gr.Button("××¤×¡ ×œ×‘×¨×™×¨×ª ××—×“×œ")
            
            save_prompt_status = gr.Markdown("")
            
            def reset_to_default():
                global current_system_prompt
                current_system_prompt = SYSTEM_PROMPT
                return SYSTEM_PROMPT, "âœ… System Prompt ××•×¤×¡ ×œ×‘×¨×™×¨×ª ××—×“×œ"
            
            save_prompt_btn.click(
                fn=save_system_prompt,
                inputs=[custom_prompt],
                outputs=[save_prompt_status]
            )
            
            reset_prompt_btn.click(
                fn=reset_to_default,
                outputs=[custom_prompt, save_prompt_status]
            )
        
        with gr.Tab("×‘×“×™×§×•×ª ××•×˜×•××˜×™×•×ª"):
            gr.Markdown("### ×”×¨×¥ ×‘×“×™×§×•×ª ××•×˜×•××˜×™×•×ª")
            gr.Markdown("×‘×—×¨ ×¨××ª ××•×¨×›×‘×•×ª ×•×”×¨×¥ ××ª ×›×œ ×”×‘×“×™×§×•×ª ×‘×‘×ª ××—×ª")
            
            with gr.Row():
                complexity_dropdown = gr.Dropdown(
                    choices=["×”×›×œ", "×¤×©×•×˜", "×‘×™× ×•× ×™", "××•×¨×›×‘"],
                    value="×”×›×œ",
                    label="×‘×—×¨ ×¨××ª ××•×¨×›×‘×•×ª"
                )
                run_tests_btn = gr.Button("×”×¨×¥ ×‘×“×™×§×•×ª", variant="primary", size="lg")
            
            test_summary = gr.Markdown("×”×¨×™×¦×” ×ª×ª×—×™×œ ×›×©×ª×œ×—×¥ ×¢×œ ×”×›×¤×ª×•×¨...")
            
            gr.Markdown("### ×ª×•×¦××•×ª ××¤×•×¨×˜×•×ª")
            results_table = gr.Dataframe(
                headers=["××¡×¤×¨", "×§×œ×˜", "×¤×œ×˜_×¦×¤×•×™", "×¤×œ×˜_×©×”×ª×§×‘×œ", "×”×ª×××”", 
                        "×¦×™×•×Ÿ_×¤×•×¨××˜", "×¦×™×•×Ÿ_×ª×—×‘×™×¨", "×¦×™×•×Ÿ_××‘×˜×—×”", "×¦×™×•×Ÿ_×›×•×œ×œ", 
                        "×¨××ª_×¡×™×›×•×Ÿ", "×”×¢×¨×•×ª"],
                label="×ª×•×¦××•×ª ×”×‘×“×™×§×•×ª",
                interactive=False
            )
            
            download_results_file = gr.File(label="×”×•×¨×“ ×§×•×‘×¥ ×ª×•×¦××•×ª CSV")
        
        with gr.Tab("×”×™×¡×˜×•×¨×™×” ×•××¢×§×‘"):
            gr.Markdown("### ×”×™×¡×˜×•×¨×™×™×ª ×‘×“×™×§×•×ª")
            gr.Markdown("×›××Ÿ ×ª×•×›×œ ×œ×¢×§×•×‘ ××—×¨×™ ×›×œ ×”×‘×“×™×§×•×ª ×©×‘×™×¦×¢×ª, ×œ×¨××•×ª ××™×š ×”-System Prompt ×”×©×ª× ×” ×•×œ×”×©×•×•×ª ×ª×•×¦××•×ª")
            
            history_display = gr.Markdown("×˜×•×¢×Ÿ ×”×™×¡×˜×•×¨×™×”...")
            
            with gr.Row():
                refresh_history_btn = gr.Button("×¨×¢× ×Ÿ ×”×™×¡×˜×•×¨×™×”", size="sm")
                download_history_btn = gr.Button("×”×•×¨×“ ×”×™×¡×˜×•×¨×™×” ××œ××” (CSV)", variant="primary")
                download_summary_btn = gr.Button("×”×•×¨×“ ×§×•×‘×¥ ×¡×™×›×•××™× (CSV)", variant="secondary")
                reset_history_btn = gr.Button("××¤×¡ ×”×™×¡×˜×•×¨×™×”", variant="stop")
            
            download_history_file = gr.File(label="×”×•×¨×“ ×§×•×‘×¥ ×”×™×¡×˜×•×¨×™×” CSV")
            download_summary_file_output = gr.File(label="×”×•×¨×“ ×§×•×‘×¥ ×¡×™×›×•××™× CSV")
            reset_status = gr.Markdown("")
    
    convert_btn.click(
        fn=lambda text: generate_command(text, current_system_prompt),
        inputs=[user_input],
        outputs=output
    )
    
    run_tests_btn.click(
        fn=lambda prompt, level: run_automated_tests(prompt, level),
        inputs=[custom_prompt, complexity_dropdown],
        outputs=[test_summary, download_results_file, history_display, results_table]
    )
    
    refresh_history_btn.click(
        fn=load_history_display,
        outputs=history_display
    )
    
    download_history_btn.click(
        fn=download_full_history,
        outputs=download_history_file
    )
    
    download_summary_btn.click(
        fn=download_summary_file,
        outputs=download_summary_file_output
    )
    
    reset_history_btn.click(
        fn=reset_history,
        outputs=[reset_status, download_history_file, download_summary_file_output]
    )
    
    demo.load(fn=load_history_display, outputs=history_display)
if __name__ == '__main__':
    port = int(os.getenv("PORT", 8080))
    demo.launch(server_name="0.0.0.0", server_port=port)