# import os
# import time
# import csv
# from dotenv import load_dotenv
# import openai
# import gradio as gr

# # ×˜×¢×Ÿ ×¡×‘×™×‘×”
# load_dotenv()
# openai.api_key = os.getenv("OPENAI_API_KEY")

# SYSTEM_PROMPT = (
#     "××ª×” ××ª×¨×’× ×”×•×¨××•×ª ×‘×©×¤×” ×˜×‘×¢×™×ª ×œ×¤×§×•×“×•×ª CLI ××ª××™××•×ª ×œ-Windows (cmd/powershell).\n"
#     "×”×ª× ×”×’ ×›×š:\n"
#     "- ×”×—×–×¨ ×¨×§ ××ª ×¤×§×•×“×ª ×”-CLI ×”××“×•×™×™×§×ª ×‘×œ×‘×“, ×‘×œ×™ ×”×¡×‘×¨×™×, ×‘×œ×™ backticks, ×‘×œ×™ ×˜×§×¡×˜ × ×•×¡×£.\n"
#     "- ×× ×”×‘×§×©×” ×œ× × ×™×ª× ×ª ×œ×”××¨×” ××• ××¡×•×›× ×ª (×›××• ×¤×§×•×“×•×ª ×©××•×—×§×•×ª ×›×•× × ×™× ×©×œ××™×), ××—×–×¨ ×‘×“×™×•×§: UNABLE_TO_PARSE\n"
#     "- ×”×©×ª××© ×‘×ª×—×‘×™×¨ ×©×œ cmd/powershell ×©×œ Windows (×œ×“×•×’××”: dir, del, ipconfig, tasklist ×•×›×•').\n"
# )

# LOG_CSV = os.path.join(os.path.dirname(__file__), "results.csv")


# def update_test_cases(input_text: str, agent_output: str):
#     """×¢×“×›×•×Ÿ test_cases.csv ×¢× ×”×¤×œ×˜ ×©×œ ×”-agent ×•×”×•×¡×¤×ª score (×ª×§×™×Ÿ/×©×’×•×™)"""
#     import pandas as pd
#     csv_path = os.path.join(os.path.dirname(__file__), "test_cases.csv")
#     try:
#         df = pd.read_csv(csv_path)
#     except Exception:
#         return
#     # ×—×¤×© ××ª ×”×©×•×¨×” ×”××ª××™××”
#     mask = df["input"] == input_text
#     if mask.any():
#         expected = df.loc[mask, "expected_output"].values[0]
#         score = "×ª×§×™×Ÿ" if agent_output.strip() == str(expected).strip() else "×©×’×•×™"
#         df.loc[mask, "score"] = score
#         df.loc[mask, "agent_output"] = agent_output
#         df.to_csv(csv_path, index=False)


# def generate_command(user_text: str) -> str:
#     """×§×¨×™××” ×œ-LLM ×¢× ×¤×¨×•××¤×˜ ××•×‘× ×” ×œ×”××¨×” ×œ×¤×§×•×“×ª CLI."""
#     if not user_text or not user_text.strip():
#         return "UNABLE_TO_PARSE"

#     messages = [
#         {"role": "system", "content": SYSTEM_PROMPT},
#         {"role": "user", "content": f"×”×•×¨××”: {user_text}\n×”×—×–×¨ ×¨×§ ××ª ×¤×§×•×“×ª ×”-CLI ×”××ª××™××”."},
#     ]

#     try:
#         resp = openai.ChatCompletion.create(
#             model="gpt-4o-mini",
#             messages=messages,
#             temperature=0.0,
#             max_tokens=150,
#         )
#         cmd = resp["choices"][0]["message"]["content"].strip()
#     except Exception as e:
#         cmd = f"UNABLE_TO_PARSE"

#     # ×¨×™×©×•× ×¤×©×•×˜
#     try:
#         with open(LOG_CSV, "a", newline='', encoding="utf-8") as f:
#             writer = csv.writer(f)
#             writer.writerow([time.strftime("%Y-%m-%d %H:%M:%S"), user_text, cmd])
#     except Exception:
#         pass

#     # ×¢×“×›×•×Ÿ test_cases.csv
#     update_test_cases(user_text, cmd)

#     return cmd


# # Gradio UI
# with gr.Blocks() as demo:
#     gr.Markdown("# Prompt Engineering ×‘×¤×¢×•×œ×” â€” ×××™×¨ ×˜×§×¡×˜ ×œ×¤×§×•×“×ª CLI")

#     with gr.Row():
#         inp = gr.Textbox(label="×”×•×¨××” ×‘×©×¤×” ×˜×‘×¢×™×ª", lines=3)
#         out = gr.Textbox(label="×¤×§×•×“×ª CLI (×ª×•×¦××”)", lines=1)

#     btn = gr.Button("×”××¨")
#     btn.click(fn=generate_command, inputs=inp, outputs=out)

#     gr.Markdown("---\n×”×ª×•×¦××•×ª × ×¨×©××•×ª ×œÖ¾results.csv ×‘×¡×¤×¨×™×™×ª ×”×¤×¨×•×™×§×˜.")


# if __name__ == '__main__':
#     port = int(os.getenv("PORT", 8080))
#     demo.launch(server_name="0.0.0.0", server_port=port)
import os
import time
import csv
from datetime import datetime
from dotenv import load_dotenv
import openai
import gradio as gr
import pandas as pd
import json

# ×˜×¢×Ÿ ×¡×‘×™×‘×”
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

SYSTEM_PROMPT = (
    "××ª×” ××ª×¨×’× ×”×•×¨××•×ª ×‘×©×¤×” ×˜×‘×¢×™×ª ×œ×¤×§×•×“×•×ª CLI ××ª××™××•×ª ×œ-Windows (cmd/powershell).\n"
    "entialAction ×›×š:\n"
  
    "- ×× ×”×‘×§×©×” ×œ× × ×™×ª× ×ª ×œ×”××¨×” ××• ××¡×•×›× ×ª (×›××• ×¤×§×•×“×•×ª ×©××•×—×§×•×ª ×›×•× × ×™× ×©×œ××™×), ××—×–×¨ ×‘×“×™×•×§: UNABLE_TO_PARSE\n"
    "- ×”×©×ª××© ×‘×ª×—×‘×™×¨ ×©×œ cmd/powershell ×©×œ Windows (×œ×“×•×’××”: dir, del, ipconfig, tasklist ×•×›×•').\n"
)

LOG_CSV = os.path.join(os.path.dirname(__file__), "results.csv")
HISTORY_JSON = os.path.join(os.path.dirname(__file__), "test_history.json")


def load_history():
    """×˜×•×¢×Ÿ ××ª ×”×”×™×¡×˜×•×¨×™×” ×©×œ ×”×‘×“×™×§×•×ª"""
    if os.path.exists(HISTORY_JSON):
        try:
            with open(HISTORY_JSON, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return []
    return []


def save_history(history):
    """×©×•××¨ ××ª ×”×”×™×¡×˜×•×¨×™×” ×©×œ ×”×‘×“×™×§×•×ª"""
    try:
        with open(HISTORY_JSON, 'w', encoding='utf-8') as f:
            json.dump(history, indent=2, fp=f, ensure_ascii=False)
    except Exception as e:
        print(f"×©×’×™××” ×‘×©××™×¨×ª ×”×™×¡×˜×•×¨×™×”: {e}")


def reset_history():
    """×××¤×¡ ××ª ×”×”×™×¡×˜×•×¨×™×”"""
    save_history([])
    return "×”×”×™×¡×˜×•×¨×™×” ××•×¤×¡×” ×‘×”×¦×œ×—×”!", None


def update_test_cases(input_text: str, agent_output: str):
    """×¢×“×›×•×Ÿ test_cases.csv ×¢× ×”×¤×œ×˜ ×©×œ ×”-agent ×•×”×•×¡×¤×ª score (×ª×§×™×Ÿ/×©×’×•×™)"""
    csv_path = os.path.join(os.path.dirname(__file__), "test_cases.csv")
    try:
        df = pd.read_csv(csv_path)
    except Exception:
        return
    # ×—×¤×© ××ª ×”×©×•×¨×” ×”××ª××™××”
    mask = df["input"] == input_text
    if mask.any():
        expected = df.loc[mask, "expected_output"].values[0]
        score = "×ª×§×™×Ÿ" if agent_output.strip() == str(expected).strip() else "×©×’×•×™"
        df.loc[mask, "score"] = score
        df.loc[mask, "agent_output"] = agent_output
        df.to_csv(csv_path, index=False)


def generate_command(user_text: str, custom_prompt: str = None) -> str:
    """×§×¨×™××” ×œ-LLM ×¢× ×¤×¨×•××¤×˜ ××•×‘× ×” ×œ×”××¨×” ×œ×¤×§×•×“×ª CLI."""
    if not user_text or not user_text.strip():
        return "UNABLE_TO_PARSE"

    prompt_to_use = custom_prompt if custom_prompt else SYSTEM_PROMPT
    
    messages = [
        {"role": "system", "content": prompt_to_use},
        {"role": "user", "content": f"×”×•×¨××”: {user_text}\n×”×—×–×¨ ×¨×§ ××ª ×¤×§×•×“×ª ×”-CLI ×”××ª××™××”."},
    ]

    try:
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.0,
            max_tokens=150,
        )
        cmd = resp.choices[0].message.content.strip()
        
        if "\`\`\`" in cmd:
            lines = cmd.split("\n")
            cleaned_lines = []
            for line in lines:
                if not line.strip().startswith("\`\`\`"):
                    cleaned_lines.append(line)
            cmd = "\n".join(cleaned_lines).strip()
            
    except Exception as e:
        print(f"[v0] Error calling OpenAI API: {e}")
        cmd = "UNABLE_TO_PARSE"

    # ×¨×™×©×•× ×¤×©×•×˜
    try:
        with open(LOG_CSV, "a", newline='', encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow([time.strftime("%Y-%m-%d %H:%M:%S"), user_text, cmd])
    except Exception:
        pass

    # ×¢×“×›×•×Ÿ test_cases.csv
    update_test_cases(user_text, cmd)

    return cmd


def run_automated_tests(custom_prompt: str, complexity_level: str):
    """××¨×™×¥ ××ª ×›×œ ×ª×¨×—×™×©×™ ×”×‘×“×™×§×” ×œ×¤×™ ×¨××ª ××•×¨×›×‘×•×ª ×•××—×–×™×¨ ×ª×•×¦××•×ª ×¢× ××—×•×–×™ ×”×¦×œ×—×”"""
    csv_path = os.path.join(os.path.dirname(__file__), "test_cases.csv")
    
    try:
        df = pd.read_csv(csv_path)
    except Exception as e:
        return f"×©×’×™××” ×‘×˜×¢×™× ×ª ×§×•×‘×¥ ×”×‘×“×™×§×•×ª: {str(e)}", None, None
    
    if complexity_level == "×¤×©×•×˜×•×ª":
        # ×‘×“×™×§×•×ª 1-5 (×¤×§×•×“×•×ª ×‘×¡×™×¡×™×•×ª)
        df = df.iloc[0:5]
    elif complexity_level == "×‘×™× ×•× ×™×•×ª":
        # ×‘×“×™×§×•×ª 6-10 (×¤×§×•×“×•×ª ×¢× ×¤×¨××˜×¨×™×)
        df = df.iloc[5:10]
    elif complexity_level == "××•×¨×›×‘×•×ª":
        # ×‘×“×™×§×•×ª 11-15 (×¤×§×•×“×•×ª ××ª×§×“××•×ª)
        df = df.iloc[10:15]
    # ××—×¨×ª (×”×›×œ) - ××¨×™×¥ ××ª ×›×œ ×”×‘×“×™×§×•×ª
    
    prompt_to_use = custom_prompt.strip() if custom_prompt and custom_prompt.strip() else SYSTEM_PROMPT
    
    results = []
    total_tests = len(df)
    passed_tests = 0
    
    for idx, row in df.iterrows():
        input_text = row['input']
        expected_output = row['expected_output']
        
        agent_output = generate_command(input_text, prompt_to_use)
        
        # ×”×©×•×•×” ××ª ×”×ª×•×¦××•×ª
        is_correct = agent_output.strip() == str(expected_output).strip()
        score = "×ª×§×™×Ÿ" if is_correct else "×©×’×•×™"
        
        if is_correct:
            passed_tests += 1
        
        results.append({
            "××¡×¤×¨": idx + 1,
            "×§×œ×˜": input_text,
            "×¤×œ×˜ ×¦×¤×•×™": expected_output,
            "×¤×œ×˜ ×©×”×ª×§×‘×œ": agent_output,
            "×ª×•×¦××”": score
        })
    
    # ×—×©×‘ ××—×•×–×™ ×”×¦×œ×—×”
    success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
    
    history = load_history()
    test_run = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "system_prompt": prompt_to_use,
        "complexity_level": complexity_level,
        "total_tests": total_tests,
        "passed_tests": passed_tests,
        "failed_tests": total_tests - passed_tests,
        "success_rate": round(success_rate, 2),
        "results": results
    }
    history.append(test_run)
    save_history(history)
    
    # ×©××•×¨ ×ª×•×¦××•×ª ×œ×§×•×‘×¥ ×¢× ×—×•×ª××ª ×–××Ÿ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_filename = f"test_results_{timestamp}.csv"
    results_path = os.path.join(os.path.dirname(__file__), results_filename)
    
    results_df = pd.DataFrame(results)
    results_df.to_csv(results_path, index=False, encoding='utf-8-sig')
    
    # ×™×¦×•×¨ ×¡×™×›×•×
    summary = f"""
    ### ×¡×™×›×•× ×‘×“×™×§×•×ª ××•×˜×•××˜×™×•×ª
    
    **×¨××ª ××•×¨×›×‘×•×ª:** {complexity_level}  
    **×¡×”"×› ×‘×“×™×§×•×ª:** {total_tests}  
    **×‘×“×™×§×•×ª ×ª×§×™× ×•×ª:** {passed_tests}  
    **×‘×“×™×§×•×ª ×©×’×•×™×•×ª:** {total_tests - passed_tests}  
    **××—×•×– ×”×¦×œ×—×”:** {success_rate:.1f}%  
    
    **×§×•×‘×¥ ×ª×•×¦××•×ª × ×©××¨:** {results_filename}
    """
    
    return summary, results_df, results_path


def download_full_history():
    """×™×•×¦×¨ ×§×•×‘×¥ CSV ×¢× ×›×œ ×”×”×™×¡×˜×•×¨×™×”"""
    history = load_history()
    
    if not history:
        return None
    
    # ×‘× ×” ×¨×©×™××” ×©×˜×•×—×” ×©×œ ×›×œ ×”×ª×•×¦××•×ª
    flat_data = []
    for run in history:
        for result in run['results']:
            flat_data.append({
                "×ª××¨×™×š ×•×©×¢×”": run['timestamp'],
                "System Prompt": run['system_prompt'][:100] + "..." if len(run['system_prompt']) > 100 else run['system_prompt'],
                "×¨××ª ××•×¨×›×‘×•×ª": run['complexity_level'],
                "××—×•×– ×”×¦×œ×—×” ×›×œ×œ×™": f"{run['success_rate']}%",
                "××¡×¤×¨ ×‘×“×™×§×”": result['××¡×¤×¨'],
                "×§×œ×˜": result['×§×œ×˜'],
                "×¤×œ×˜ ×¦×¤×•×™": result['×¤×œ×˜ ×¦×¤×•×™'],
                "×¤×œ×˜ ×©×”×ª×§×‘×œ": result['×¤×œ×˜ ×©×”×ª×§×‘×œ'],
                "×ª×•×¦××”": result['×ª×•×¦××”']
            })
    
    # ×¦×•×¨ DataFrame ×•×©××•×¨
    df = pd.DataFrame(flat_data)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"full_history_{timestamp}.csv"
    filepath = os.path.join(os.path.dirname(__file__), filename)
    df.to_csv(filepath, index=False, encoding='utf-8-sig')
    
    return filepath


def show_history_summary():
    """××¦×™×’ ×¡×™×›×•× ×©×œ ×›×œ ×”×”×™×¡×˜×•×¨×™×”"""
    history = load_history()
    
    if not history:
        return "××™×Ÿ ×¢×“×™×™×Ÿ ×”×™×¡×˜×•×¨×™×” ×©×œ ×‘×“×™×§×•×ª.", None
    
    summary_data = []
    for idx, run in enumerate(history, 1):
        summary_data.append({
            "×¨×™×¦×” #": idx,
            "×ª××¨×™×š ×•×©×¢×”": run['timestamp'],
            "×¨××ª ××•×¨×›×‘×•×ª": run['complexity_level'],
            "×¡×”"×› ×‘×“×™×§×•×ª": run['total_tests'],
            "×‘×“×™×§×•×ª ×ª×§×™× ×•×ª": run['passed_tests'],
            "××—×•×– ×”×¦×œ×—×”": f"{run['success_rate']}%",
            "System Prompt (100 ×ª×•×•×™× ×¨××©×•× ×™×)": run['system_prompt'][:100] + "..."
        })
    
    df = pd.DataFrame(summary_data)
    
    summary_text = f"""
    ### ×¡×™×›×•× ×”×™×¡×˜×•×¨×™×”
    
    **×¡×”"×› ×¨×™×¦×•×ª:** {len(history)}  
    **××—×•×– ×”×¦×œ×—×” ×××•×¦×¢:** {sum(r['success_rate'] for r in history) / len(history):.1f}%
    """
    
    return summary_text, df


with gr.Blocks(theme=gr.themes.Soft(), css="""
    .gradio-container {
        max-width: 1400px !important;
    }
    .success-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        font-weight: bold;
        text-align: center;
        margin: 10px 0;
    }
    .header-title {
        text-align: center;
        color: #667eea;
        font-size: 2.5em;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .subtitle {
        text-align: center;
        color: #666;
        font-size: 1.1em;
        margin-bottom: 30px;
    }
    .prompt-box {
        border: 2px solid #667eea;
        border-radius: 8px;
        padding: 15px;
        background: #f8f9ff;
    }
""") as demo:
    
    gr.HTML('<div class="header-title">ğŸ¤– ×××™×¨ ×˜×§×¡×˜ ×œ×¤×§×•×“×•×ª CLI</div>')
    gr.HTML('<div class="subtitle">Prompt Engineering Agent - ×”××¨×ª ×”×•×¨××•×ª ×‘×©×¤×” ×˜×‘×¢×™×ª ×œ×¤×§×•×“×•×ª Windows</div>')
    
    with gr.Tabs():
        with gr.Tab("âš™ï¸ ×”×’×“×¨×•×ª System Prompt"):
            gr.Markdown("### ×¢×¨×•×š ××ª ×”-System Prompt ×œ×¤×™ ×¦×•×¨×›×™×š")
            gr.Markdown("System Prompt ×§×•×‘×¢ ××™×š ×”-Agent ××ª×¨×’× ×”×•×¨××•×ª ×œ×¤×§×•×“×•×ª CLI. × ×¡×” ×’×¨×¡××•×ª ×©×•× ×•×ª ×•×‘×“×•×§ ××™×–×• ×¢×•×‘×“×ª ×”×›×™ ×˜×•×‘!")
            
            system_prompt_input = gr.Textbox(
                label="System Prompt",
                value=SYSTEM_PROMPT,
                lines=10,
                placeholder="×”×›× ×¡ ××ª ×”-System Prompt ×”××•×ª×× ×©×œ×š ×›××Ÿ...",
                elem_classes="prompt-box"
            )
            
            gr.Markdown("---")
            gr.Markdown("ğŸ’¡ **×˜×™×¤:** ××—×¨×™ ×©×ª×©× ×” ××ª ×”-System Prompt, ×¢×‘×•×¨ ×œ×˜××‘ '×‘×“×™×§×•×ª ××•×˜×•××˜×™×•×ª' ×›×“×™ ×œ×‘×“×•×§ ××ª ×”×©×¤×¢×ª ×”×©×™× ×•×™")
        
        with gr.Tab("ğŸ”¨ ×”××¨×ª ×¤×§×•×“×” ×™×—×™×“×”"):
            gr.Markdown("### ×”×–×Ÿ ×”×•×¨××” ×‘×©×¤×” ×˜×‘×¢×™×ª ×•×§×‘×œ ×¤×§×•×“×ª CLI ××ª××™××”")
            
            with gr.Row():
                with gr.Column(scale=2):
                    inp = gr.Textbox(
                        label="×”×•×¨××” ×‘×©×¤×” ×˜×‘×¢×™×ª",
                        placeholder='×œ×“×•×’××”: "××” ×›×ª×•×‘×ª ×”-IP ×©×œ ×”××—×©×‘ ×©×œ×™"',
                        lines=4
                    )
                    btn = gr.Button("×”××¨ ×œ×¤×§×•×“×ª CLI", variant="primary", size="lg")
                
                with gr.Column(scale=2):
                    out = gr.Textbox(
                        label="×¤×§×•×“×ª CLI (×ª×•×¦××”)",
                        lines=4,
                        interactive=False
                    )
            
            btn.click(fn=lambda text, prompt: generate_command(text, prompt), 
                     inputs=[inp, system_prompt_input], 
                     outputs=out)
            
            gr.Markdown("---")
            gr.Markdown("ğŸ’¡ **×˜×™×¤:** ×”×¤×§×•×“×•×ª × ×©××¨×•×ª ××•×˜×•××˜×™×ª ×‘×§×•×‘×¥ results.csv")
        
        with gr.Tab("ğŸ§ª ×‘×“×™×§×•×ª ××•×˜×•××˜×™×•×ª"):
            gr.Markdown("### ×”×¨×¥ ×‘×“×™×§×•×ª ×œ×¤×™ ×¨××ª ××•×¨×›×‘×•×ª ×•×¢×§×•×‘ ××—×¨×™ ×‘×™×¦×•×¢×™×")
            
            with gr.Row():
                with gr.Column():
                    complexity_selector = gr.Radio(
                        choices=["×¤×©×•×˜×•×ª", "×‘×™× ×•× ×™×•×ª", "××•×¨×›×‘×•×ª", "×”×›×œ"],
                        value="×”×›×œ",
                        label="×¨××ª ××•×¨×›×‘×•×ª ×”×¤×§×•×“×•×ª",
                        info="×‘×—×¨ ××™×–×” ×¡×•×’ ×¤×§×•×“×•×ª ×œ×‘×“×•×§"
                    )
                    
                    test_btn = gr.Button("â–¶ï¸ ×”×¨×¥ ×‘×“×™×§×•×ª ××•×˜×•××˜×™×•×ª", variant="primary", size="lg")
            
            summary_output = gr.Markdown(label="×¡×™×›×•× ×ª×•×¦××•×ª")
            
            results_table = gr.Dataframe(
                label="×ª×•×¦××•×ª ××¤×•×¨×˜×•×ª",
                wrap=True,
                interactive=False
            )
            
            with gr.Row():
                download_btn = gr.File(label="ğŸ“¥ ×”×•×¨×“ ×§×•×‘×¥ ×ª×•×¦××•×ª ×¨×™×¦×” × ×•×›×—×™×ª")
            
            test_btn.click(
                fn=run_automated_tests,
                inputs=[system_prompt_input, complexity_selector],
                outputs=[summary_output, results_table, download_btn]
            )
            
            gr.Markdown("---")
            gr.Markdown("""
            **ğŸ“ ×”×¡×‘×¨ ×¢×œ ×¨××•×ª ××•×¨×›×‘×•×ª:**
            - **×¤×©×•×˜×•×ª:** ×‘×“×™×§×•×ª 1-5 (×¤×§×•×“×•×ª ×‘×¡×™×¡×™×•×ª ×›××• ipconfig, tasklist)
            - **×‘×™× ×•× ×™×•×ª:** ×‘×“×™×§×•×ª 6-10 (×¤×§×•×“×•×ª ×¢× ×¤×¨××˜×¨×™× ×›××• copy, ren)
            - **××•×¨×›×‘×•×ª:** ×‘×“×™×§×•×ª 11-15 (×¤×§×•×“×•×ª ××ª×§×“××•×ª ×¢× pipes ×•×¡×™× ×•× ×™×)
            - **×”×›×œ:** ××¨×™×¥ ××ª ×›×œ 15 ×”×‘×“×™×§×•×ª
            """)
        
        with gr.Tab("ğŸ“Š ×”×™×¡×˜×•×¨×™×™×ª ×‘×“×™×§×•×ª"):
            gr.Markdown("### ×¢×§×•×‘ ××—×¨×™ ×›×œ ×”×¨×™×¦×•×ª ×•×¨××” ××™×š ×”-System Prompt ××©×¤×™×¢ ×¢×œ ×”×ª×•×¦××•×ª")
            
            with gr.Row():
                show_history_btn = gr.Button("ğŸ” ×”×¦×’ ×”×™×¡×˜×•×¨×™×”", variant="secondary")
                download_history_btn = gr.Button("ğŸ“¥ ×”×•×¨×“ ×”×™×¡×˜×•×¨×™×” ××œ××” (CSV)", variant="primary")
                reset_history_btn = gr.Button("ğŸ—‘ï¸ ××¤×¡ ×”×™×¡×˜×•×¨×™×”", variant="stop")
            
            history_summary = gr.Markdown(label="×¡×™×›×•× ×”×™×¡×˜×•×¨×™×”")
            history_table = gr.Dataframe(
                label="×›×œ ×”×¨×™×¦×•×ª",
                wrap=True,
                interactive=False
            )
            
            history_download = gr.File(label="×§×•×‘×¥ ×”×™×¡×˜×•×¨×™×” ××œ××”")
            
            show_history_btn.click(
                fn=show_history_summary,
                inputs=[],
                outputs=[history_summary, history_table]
            )
            
            download_history_btn.click(
                fn=download_full_history,
                inputs=[],
                outputs=history_download
            )
            
            reset_history_btn.click(
                fn=reset_history,
                inputs=[],
                outputs=[history_summary, history_table]
            )
            
            gr.Markdown("---")
            gr.Markdown("""
            **ğŸ“ˆ ××™×š ×œ×”×©×ª××© ×‘×”×™×¡×˜×•×¨×™×”:**
            1. ×”×¨×¥ ×‘×“×™×§×•×ª ×¢× system prompts ×©×•× ×™×
            2. ×”×©×•×•×” ××ª ××—×•×–×™ ×”×¦×œ×—×” ×‘×™×Ÿ ×’×¨×¡××•×ª
            3. ×”×•×¨×“ ××ª ×”×”×™×¡×˜×•×¨×™×” ×”××œ××” ×œ× ×™×ª×•×— ××¢××™×§
            4. ×›×©××•×¦× system prompt ×©×¢×•×‘×“ ×˜×•×‘ - ×©××•×¨ ××•×ª×•!
            5. ××¤×¡ ××ª ×”×”×™×¡×˜×•×¨×™×” ×›×©×¨×•×¦×” ×œ×”×ª×—×™×œ × ×™×¡×•×™ ×—×“×©
            """)


if __name__ == '__main__':
    port = int(os.getenv("PORT", 8080))
    demo.launch(server_name="0.0.0.0", server_port=port)
